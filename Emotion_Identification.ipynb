{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jj7258/Emotion-Identification/blob/main/Emotion_Identification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Emotion Identification\n",
        "\n",
        "In this notebook, we'll use machine learning to categorise the emotions included in audio recordings. After extracting characteristics from audio recordings with the librosa framework, we will train a neural network to categorise emotions.\n"
      ],
      "metadata": {
        "id": "Ilm9QATnAM3M"
      },
      "id": "Ilm9QATnAM3M"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing libraries\n",
        "\n",
        "First, we will start by importing the necessary libraries and ignoring warnings.\n",
        "\n"
      ],
      "metadata": {
        "id": "yrKwaUwEANaB"
      },
      "id": "yrKwaUwEANaB"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7c67552e",
      "metadata": {
        "id": "7c67552e"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import librosa\n",
        "import os, glob, pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from os import listdir\n",
        "\n",
        "import librosa.display"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extracting audio filenames and emotions\n",
        "\n",
        "We start by collecting the audio filenames and corresponding emotions in separate lists. The path of the audio files and their emotions are stored in the variables audio_path and audio_emotion respectively. The emotions are extracted from the filenames."
      ],
      "metadata": {
        "id": "0tb7S5fWHBjX"
      },
      "id": "0tb7S5fWHBjX"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqP0GtLaUdzF",
        "outputId": "d7958e76-2334-4799-aad9-c5ebec106c02"
      },
      "id": "MqP0GtLaUdzF",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "38c15aa0",
      "metadata": {
        "id": "38c15aa0"
      },
      "outputs": [],
      "source": [
        "path = 'drive/MyDrive/AudioWAV/'\n",
        "audio_path = []\n",
        "audio_emotion = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "23aa9eb0",
      "metadata": {
        "id": "23aa9eb0"
      },
      "outputs": [],
      "source": [
        "# collects all the audio filename in the variable 'path'\n",
        "directory_path = listdir(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f75da296",
      "metadata": {
        "id": "f75da296"
      },
      "outputs": [],
      "source": [
        "for audio in directory_path:\n",
        "    audio_path.append(path + audio)\n",
        "    emotion = audio.split('_')\n",
        "    if emotion[2] == 'SAD':\n",
        "        audio_emotion.append(\"sad\")\n",
        "    elif emotion[2] == 'ANG':\n",
        "        audio_emotion.append(\"angry\")\n",
        "    elif emotion[2] == 'DIS':\n",
        "        audio_emotion.append(\"disgust\")\n",
        "    elif emotion[2] == 'NEU':\n",
        "        audio_emotion.append(\"neutral\")\n",
        "    elif emotion[2] == 'HAP':\n",
        "        audio_emotion.append(\"happy\")\n",
        "    elif emotion[2] == 'FEA':\n",
        "        audio_emotion.append(\"fear\")\n",
        "    else:\n",
        "        audio_emotion.append(\"unknown\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e1109eb6",
      "metadata": {
        "id": "e1109eb6",
        "outputId": "699052d3-f14d-4cc8-ea69-1c57de17912f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                         Path Emotions\n",
            "0  drive/MyDrive/AudioWAV/1080_IEO_ANG_MD.wav    angry\n",
            "1  drive/MyDrive/AudioWAV/1079_IWW_DIS_XX.wav  disgust\n",
            "2  drive/MyDrive/AudioWAV/1079_IEO_DIS_LO.wav  disgust\n",
            "3  drive/MyDrive/AudioWAV/1080_IEO_HAP_LO.wav    happy\n",
            "4  drive/MyDrive/AudioWAV/1079_DFA_DIS_XX.wav  disgust\n"
          ]
        }
      ],
      "source": [
        "emotion_dataset = pd.DataFrame(audio_emotion, columns=['Emotions'])\n",
        "audio_path_dataset = pd.DataFrame(audio_path, columns=['Path'])\n",
        "dataset = pd.concat([audio_path_dataset, emotion_dataset], axis= 1)\n",
        "\n",
        "print(dataset.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing emotions\n",
        "\n",
        "We can visualize the emotions of the audio files using a histogram."
      ],
      "metadata": {
        "id": "LTD5Bu1WYFuS"
      },
      "id": "LTD5Bu1WYFuS"
    },
    {
      "cell_type": "code",
      "source": [
        "# counting audio categorized by emotions\n",
        "plt.figure(figsize=(6,6), dpi=80)\n",
        "plt.title(\"Emotion Count\", size=16)\n",
        "plt.xlabel('Emotions', size = 12)\n",
        "plt.ylabel('Count', size = 12)\n",
        "sns.histplot(dataset.Emotions, color='#F19C0E')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "S4IPzMn7YCnm",
        "outputId": "204c1123-4b25-4b79-c964-66e3252fbc08"
      },
      "id": "S4IPzMn7YCnm",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f8409648eb0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 480x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extracting features from audio files\n",
        "\n",
        "Now, we will extract the necessary features from the audio files. We will extract the MFCC and Mel features from the audio files and store them in a dataframe along with the emotion label for each audio file."
      ],
      "metadata": {
        "id": "wXOaQ2vSYM8W"
      },
      "id": "wXOaQ2vSYM8W"
    },
    {
      "cell_type": "code",
      "source": [
        "X, Y = [], []\n",
        "print(\"Feature processing...\")\n",
        "\n",
        "for path, emo, index in zip(dataset.Path, dataset.Emotions, range(len(dataset))):\n",
        "    value, sample = librosa.load(path)\n",
        "    # noise injection\n",
        "    noise_amp = 0.035 * np.random.uniform() * np.amax(value)\n",
        "    value = value + noise_amp * np.random.normal(size=value.shape[0])\n",
        "    # mfcc\n",
        "    mfcc = librosa.feature.mfcc(y=value, sr= sample, n_mfcc=13, n_fft=200, hop_length=512)\n",
        "    mfcc = np.ravel(mfcc.T)\n",
        "    # mel\n",
        "    mel = librosa.feature.melspectrogram(y=value, sr=sample, hop_length = 256, n_fft = 512, n_mels=64)\n",
        "    mel = librosa.power_to_db(mel ** 2)\n",
        "    mel = np.ravel(mel).T\n",
        "    result = np.array([])\n",
        "    result = np.hstack((result, mfcc, mel))\n",
        "  \n",
        "    result = np.array(result)\n",
        "    X.append(result)\n",
        "    Y.append(emo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PI7w0uCeYUGJ",
        "outputId": "ff4491c9-174c-4024-8649-acf52142d8b2"
      },
      "id": "PI7w0uCeYUGJ",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature processing...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "extracted_audio_df = pd.DataFrame(X)\n",
        "extracted_audio_df[\"emotion_of_audio\"] = Y\n",
        "print(extracted_audio_df.shape)\n",
        "print(extracted_audio_df.tail(10))\n",
        "extracted_audio_df = extracted_audio_df.fillna(0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azFnBekuYWnc",
        "outputId": "a568b405-34cd-4168-8561-fbd5679e3a56"
      },
      "id": "azFnBekuYWnc",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7442, 30457)\n",
            "               0          1          2          3          4          5  \\\n",
            "7432 -795.797579 -32.120075  23.046704  20.396499  20.419560  20.065688   \n",
            "7433 -828.718147   8.093675 -23.101560  35.270118   5.724489   0.590736   \n",
            "7434 -515.626523 -83.889300  -2.958627  15.429383  20.102983  -4.664043   \n",
            "7435 -701.837997 -75.252873   1.833795  13.191461  10.656882  -5.137151   \n",
            "7436 -781.860726 -22.087140  17.749035  35.647971   7.380920  29.136822   \n",
            "7437 -769.889357 -16.823679  -2.288254   7.396960  17.332083 -21.256827   \n",
            "7438 -634.013960 -40.000047   9.136871  12.637184  22.042133   2.734228   \n",
            "7439 -829.959454  13.008016  12.243181  20.267717  10.327020  19.111259   \n",
            "7440 -604.716890 -84.585232 -31.522639  34.604999  30.765686 -16.539457   \n",
            "7441 -649.839321 -56.461303  -7.821440  15.667959   9.210937  14.409639   \n",
            "\n",
            "              6          7          8          9  ...  30447  30448  30449  \\\n",
            "7432 -13.830764  -8.657091 -15.793977  -8.671057  ...    NaN    NaN    NaN   \n",
            "7433 -27.471593  -0.100910  -7.841943  -1.410003  ...    NaN    NaN    NaN   \n",
            "7434  -9.763974  -9.562189 -16.733033   6.206821  ...    NaN    NaN    NaN   \n",
            "7435 -10.521038   0.244821 -21.581825  -0.247533  ...    NaN    NaN    NaN   \n",
            "7436  11.342374  -9.018313  -2.479122   2.314040  ...    NaN    NaN    NaN   \n",
            "7437 -31.912696  -5.841048 -14.743514 -19.662572  ...    NaN    NaN    NaN   \n",
            "7438 -20.439457 -11.721606  -1.420334 -11.237269  ...    NaN    NaN    NaN   \n",
            "7439 -27.509346 -11.189980  -0.316881  10.235978  ...    NaN    NaN    NaN   \n",
            "7440 -12.837433   2.065707   3.837792 -23.797528  ...    NaN    NaN    NaN   \n",
            "7441  -9.182652  -4.196272  -3.655542 -12.785118  ...    NaN    NaN    NaN   \n",
            "\n",
            "      30450  30451  30452  30453  30454  30455  emotion_of_audio  \n",
            "7432    NaN    NaN    NaN    NaN    NaN    NaN              fear  \n",
            "7433    NaN    NaN    NaN    NaN    NaN    NaN           neutral  \n",
            "7434    NaN    NaN    NaN    NaN    NaN    NaN             happy  \n",
            "7435    NaN    NaN    NaN    NaN    NaN    NaN           neutral  \n",
            "7436    NaN    NaN    NaN    NaN    NaN    NaN           neutral  \n",
            "7437    NaN    NaN    NaN    NaN    NaN    NaN              fear  \n",
            "7438    NaN    NaN    NaN    NaN    NaN    NaN           disgust  \n",
            "7439    NaN    NaN    NaN    NaN    NaN    NaN           neutral  \n",
            "7440    NaN    NaN    NaN    NaN    NaN    NaN             happy  \n",
            "7441    NaN    NaN    NaN    NaN    NaN    NaN             happy  \n",
            "\n",
            "[10 rows x 30457 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing data for training\n",
        "\n",
        "Now, we will split the data into training and testing sets and standardize the data using the StandardScaler function.\n"
      ],
      "metadata": {
        "id": "D7f1-KylYY1v"
      },
      "id": "D7f1-KylYY1v"
    },
    {
      "cell_type": "code",
      "source": [
        "# preparing to train\n",
        "X = extracted_audio_df.drop(labels='emotion_of_audio', axis= 1)\n",
        "Y = extracted_audio_df['emotion_of_audio']\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(np.array(X), Y, test_size=0.2)"
      ],
      "metadata": {
        "id": "Se-qEEcyYZ5Z"
      },
      "id": "Se-qEEcyYZ5Z",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_test = scaler.transform(x_test)"
      ],
      "metadata": {
        "id": "KL6OIwJwYb-1"
      },
      "id": "KL6OIwJwYb-1",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Model\n",
        "\n",
        "Now, we will create an instance of the MLP Classifier from the sklearn.neural_network library and fit it to the training data."
      ],
      "metadata": {
        "id": "9_8kJwJIYgAu"
      },
      "id": "9_8kJwJIYgAu"
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_model = MLPClassifier(activation='relu',\n",
        "                         solver='sgd',\n",
        "                         hidden_layer_sizes=100, \n",
        "                         alpha=0.839903176695813,\n",
        "                         batch_size=150,\n",
        "                         learning_rate='adaptive',\n",
        "                         max_iter=100000)\n",
        "# Fitting mlp model\n",
        "mlp_model.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "dwutyPUcYezG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86f4f054-db4e-42a0-b287-db3b3cbdcffd"
      },
      "id": "dwutyPUcYezG",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(alpha=0.839903176695813, batch_size=150, hidden_layer_sizes=100,\n",
              "              learning_rate='adaptive', max_iter=100000, solver='sgd')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating the Model\n",
        "\n",
        "Now that the model is trained, we will evaluate its performance on the test data. We will use the accuracy_score function from the sklearn.metrics library to calculate the accuracy of the model."
      ],
      "metadata": {
        "id": "S5qged10YhjA"
      },
      "id": "S5qged10YhjA"
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = mlp_model.predict(x_test)\n",
        "accuracy=accuracy_score(y_true=y_test, y_pred=y_pred)\n",
        "\n",
        "print(\"\\nModel:{}    Accuracy: {:.2f}%\".\n",
        "          format(type(mlp_model).__name__ , accuracy*100))"
      ],
      "metadata": {
        "id": "R5BjHr6kYhV3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "657f905f-be97-44f5-ce7b-e2b917dfa7a1"
      },
      "id": "R5BjHr6kYhV3",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model:MLPClassifier    Accuracy: 40.43%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Predictions\n",
        "\n",
        "Finally, we can print out the predictions made by the model on the testing set."
      ],
      "metadata": {
        "id": "nJDI8ofHYka6"
      },
      "id": "nJDI8ofHYka6"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The Model's Prediction \")\n",
        "print(\"<<<===========================================>>>\")\n",
        "df = pd.DataFrame({'Actual': y_test, 'Predict': y_pred})\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "2ErAxBOpYj4-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24a1ff68-60f4-42de-f599-4c779ebb7825"
      },
      "id": "2ErAxBOpYj4-",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Model's Prediction \n",
            "<<<===========================================>>>\n",
            "       Actual  Predict\n",
            "2383    angry  neutral\n",
            "6719    happy    happy\n",
            "908     happy     fear\n",
            "3067  disgust    angry\n",
            "3165      sad      sad\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}